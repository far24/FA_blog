---
title: 'R webscape '
author: Fahim Ahmed
date: '2020-08-13'
slug: r-webscape
categories:
  - R
  - data collection
  - webscape
tags:
  - R
  - rvest
  - httr
  - xml2
editor_options: 
  chunk_output_type: console
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<div id="r-webscape" class="section level1">
<h1>R webscape</h1>
<div id="why-we-would-do-webscraps" class="section level3">
<h3>why we would do webscraps?</h3>
<ul>
<li>quickly get data from website that has multiple pages</li>
</ul>
</div>
<div id="some-of-the-sites-offering-webscraping-services" class="section level3">
<h3>some of the sites offering webscraping services</h3>
<ul>
<li>htttps://listly.io</li>
<li>htttps://webhose.io/</li>
<li>htttps://scrapinghub.com/</li>
<li>htttps://webscraping.com</li>
</ul>
</div>
<div id="approach" class="section level2">
<h2>Approach</h2>
<p>The approach of this tutorial is to learn by working with an example. So, different types of websites are presented that would be used to extract information. The type of website refers to the technology it uses. For example, <strong>html+css only</strong>, <strong>html+css+javascript</strong>, <strong>interaction with a website</strong> to get the data etc.</p>
</div>
<div id="assumption" class="section level2">
<h2>Assumption</h2>
<p>A few assumption is made while you follow along the tutorial:</p>
<ul>
<li>you know basics of HTML code</li>
<li>you know basics of XML code</li>
<li>you know how to use Google Chrome Developer</li>
</ul>
</div>
<div id="r-packages-used-for-webscraping" class="section level2">
<h2>R packages used for webscraping</h2>
<ul>
<li>rvest</li>
<li>xml</li>
</ul>
</div>
<div id="websites-to-scrap" class="section level2">
<h2>Websites to scrap</h2>
<ul>
<li><a href="%22https://www.skysports.com/premier-league-table/2019%22">Premier League Standing</a></li>
</ul>
</div>
<div id="step-by-step-actions" class="section level2">
<h2>Step-by-Step actions</h2>
<pre class="r"><code>knitr::opts_chunk$set(warning = FALSE,
                      message = FALSE)</code></pre>
<div id="load-libraries" class="section level3">
<h3>Load Libraries</h3>
<p>We are using the “rvest” and “xml2” package to scrape the website. For data wrangling, the “dplyr” package will be used.</p>
<pre class="r"><code>library(rvest) # reading websites
library(dplyr) # for data wrangling
library(xml2) # 
library(ggplot2)  # for plotting</code></pre>
</div>
<div id="parse-the-website" class="section level3">
<h3>Parse the Website</h3>
<p>In this example the English Premier Legue (EPL) table for standing in different seasons are recorded in HTML Table. First, the webpage address (URL) is noted and then it is passed into the read_html function from the xml2 package.</p>
<pre class="r"><code># get the page address
wbpage &lt;- &quot;https://www.skysports.com/premier-league-table/2016&quot;

# read the html page
wbpage_read_html &lt;- xml2::read_html(wbpage)</code></pre>
<p>Now, we need to find where is the table located in the webpage and how to select it using html tag or css properties. Use the developer tool in chrome (or any other browser)</p>
<pre class="r"><code>untidy_data &lt;-
  wbpage_read_html %&gt;% 
  # select node &#39;div&#39; from html document
  rvest::html_nodes(&#39;div&#39;) %&gt;% 
  # find &lt;td&gt; that contains the class = &quot;standing-table_cell&quot;
  xml2::xml_find_all(&quot;//td[contains(@class,&#39;standing-table__cell&#39;)]&quot;) %&gt;% 
  # extract the text for the scraped table
  rvest::html_text()

# check what is scraped so far
head(untidy_data)</code></pre>
<pre><code>## [1] &quot;1&quot;                                            
## [2] &quot;\n\n                Chelsea\n        \n      &quot;
## [3] &quot;38&quot;                                           
## [4] &quot;30&quot;                                           
## [5] &quot;3&quot;                                            
## [6] &quot;5&quot;</code></pre>
<p>Looking at the untidy data set (it’s a vector), it seems we have all the values but not usable for further exploration. Next, this untidy vector data is transformed into a tidy data. Every 11 elements in the vector corresponds to one team. So, for 20 teams in the EPL, we have 11*20=220 elements in the vector. The vector dataset is splitted after every 11th position to make the new dataset. In addition, it is transformed into a dataframe with columns names. To sanitize the table, datatypes are indicated using hablar package and every string is trimmed for whitespace.</p>
<pre class="r"><code># divide the vector into 11 columns and 20 rows
table_dt &lt;- cbind.data.frame(split(untidy_data, rep(1:11)), stringsAsFactors=F)[1:10]

# add column names
column_names &lt;- c(&quot;rank&quot;, &quot;team_name&quot;, &quot;played&quot;, &quot;win&quot;, &quot;draw&quot;, &quot;lost&quot;, &quot;scored&quot;, &quot;conceded&quot;, &quot;goal_diff&quot;, &quot;points&quot;)

colnames(table_dt) &lt;- column_names

# indicate data types, trim whitespace, add season column
table_dt &lt;- 
  table_dt %&gt;%
  # transform to simple classes: date, numeric, and character
  hablar::retype() %&gt;%
  mutate(across(where(is.character), stringr::str_trim)) %&gt;% 
  mutate(season = 2019)

head(table_dt)</code></pre>
<pre><code>## # A tibble: 6 x 11
##    rank team_name played   win  draw  lost scored conceded goal_diff points
##   &lt;int&gt; &lt;chr&gt;      &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;int&gt;    &lt;int&gt;     &lt;int&gt;  &lt;int&gt;
## 1     1 Chelsea       38    30     3     5     85       33        52     93
## 2     2 Tottenha~     38    26     8     4     86       26        60     86
## 3     3 Manchest~     38    23     9     6     80       39        41     78
## 4     4 Liverpool     38    22    10     6     78       42        36     76
## 5     5 Arsenal       38    23     6     9     77       44        33     75
## 6     6 Manchest~     38    18    15     5     54       29        25     69
## # ... with 1 more variable: season &lt;dbl&gt;</code></pre>
<p>Now, that a fantastic looking table!!</p>
<p>This webscraping could have done manually. Anyone can just copy and paste it. The beauty of using a programming language is that, we can use it to scrape multiple pages. This tutorial will introduce that too.</p>
<p>The procedure to scrape other seasons as follows:</p>
<ul>
<li>loop through the webpages for different years</li>
<li>parsing the webpages to get texts (as vector data)</li>
<li>tranform vector data to dataframe with teams information as observations for each season</li>
</ul>
<pre class="r"><code>get_webpage &lt;- function(page_address) {
    untidy_data &lt;-
      read_html(page_address) %&gt;% # read html
      rvest::html_nodes(&#39;tbody&#39;) %&gt;% # node extraction
      xml2::xml_find_all(&quot;//td[contains(@class,&#39;standing-table__cell&#39;)]&quot;) %&gt;% # manual entry
      rvest::html_text()
    
    table_dt &lt;- cbind.data.frame(split(untidy_data, rep(1:11)),
                                 stringsAsFactors = F)[1:10]
    return(table_dt)
  
}</code></pre>
<pre class="r"><code># function::get_epl_data(seasons)
# This function takes seasons as input
# outputs a table for dataframe 

get_epl_data &lt;- function(seasons, result_df) {
  for (i in seq(1,length(seasons))) {
    year = seasons[i]
    print(year)
    
    # get webpage address
    wbpage &lt;- paste0(&quot;https://www.skysports.com/premier-league-table/&quot;, year)
    print(wbpage)
    
    untidy_dt &lt;- get_webpage(wbpage)
    
    # tranform vector to dataframe
    table_dt &lt;-
      untidy_dt %&gt;%
      hablar::retype() %&gt;%
      mutate(across(where(is.character), stringr::str_trim)) %&gt;%
      mutate(season = year)
  
    result_df &lt;- rbind(result_df, table_dt)  
  
  } # end for loop for years in seasons
  return(result_df)
} # end function</code></pre>
<p>Let’s scrape the epl table from the website from 2015 to 2019 using the “get_epl_data” function.</p>
<pre class="r"><code># create an empty dataframe save the results
dt &lt;- data.frame()
dt &lt;- get_epl_data(seasons = c(2015:2019), result_df = dt)</code></pre>
<pre><code>## [1] 2015
## [1] &quot;https://www.skysports.com/premier-league-table/2015&quot;
## [1] 2016
## [1] &quot;https://www.skysports.com/premier-league-table/2016&quot;
## [1] 2017
## [1] &quot;https://www.skysports.com/premier-league-table/2017&quot;
## [1] 2018
## [1] &quot;https://www.skysports.com/premier-league-table/2018&quot;
## [1] 2019
## [1] &quot;https://www.skysports.com/premier-league-table/2019&quot;</code></pre>
<pre class="r"><code># change the column names for further use 
column_names &lt;- c(&quot;rank&quot;, &quot;team_name&quot;,&quot;played&quot;, &quot;win&quot;, &quot;draw&quot;,&quot;lost&quot;,
                      &quot;scored&quot;, &quot;conceded&quot;, &quot;goal_diff&quot;, &quot;points&quot;, &quot;season&quot;
                      )
colnames(dt) &lt;- column_names

head(dt)</code></pre>
<pre><code>## # A tibble: 6 x 11
##    rank team_name played   win  draw  lost scored conceded goal_diff points
##   &lt;int&gt; &lt;chr&gt;      &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;int&gt;    &lt;int&gt;     &lt;int&gt;  &lt;int&gt;
## 1     1 Leiceste~     38    23    12     3     68       36        32     81
## 2     2 Arsenal       38    20    11     7     65       36        29     71
## 3     3 Tottenha~     38    19    13     6     69       35        34     70
## 4     4 Manchest~     38    19     9    10     71       41        30     66
## 5     5 Manchest~     38    19     9    10     49       35        14     66
## 6     6 Southamp~     38    18     9    11     59       41        18     63
## # ... with 1 more variable: season &lt;int&gt;</code></pre>
<p>Now, let’s use this dataset to plot the ranking of the teams from 2015 and 2019. The “Bump” chart would show us how teams ranking in the table changed over the last five years.</p>
<pre class="r"><code>dt %&gt;% 
  filter(rank &lt;= 6) %&gt;%
  ggplot(
    aes(x = season, y = rank, group = team_name)) + theme_bw() +
      geom_line(aes(
        color = team_name,
        alpha = 1
      ),
      size = 2) +
      geom_point(aes(
        color = team_name,
        alpha = 1
      ),
      size = 4) +
      scale_x_continuous(breaks = c(2015:2019),
                         expand = c(0.85, 0)) +
      scale_y_reverse(breaks = 1:20) +
      labs(x = &quot;season&quot;,
           y = &quot;rank&quot;,
           title = &quot;Top 6 EPL Teams: 2015 - 2019&quot;)</code></pre>
<p><img src="public/post/2020-08-13-r-webscape_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
</div>
</div>
</div>
